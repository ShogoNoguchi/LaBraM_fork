{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPnBC7KGWQhyqr0lzJlahoq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShogoNoguchi/LaBraM_fork/blob/main/%EF%BC%88%E9%80%B2%E6%8D%97%EF%BC%89%EF%BD%9E%E5%A4%A7%E8%A6%8F%E6%A8%A1%E6%A7%8B%E9%80%A0%E3%81%AE%E7%89%B9%E5%AE%9A%E3%81%A8%E4%BF%AE%E6%AD%A3%E9%A0%85%E7%9B%AE%E3%81%AE%E7%99%BA%E8%A6%8B%EF%BD%9E.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Driveをマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JR96Dz5cSUoF",
        "outputId": "c10cd01c-4d8c-42c7-9de2-d2216585813e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "論文を熟読し、GitHubのREAD MEを読んで課題1つ目を処理する方法を調べた。\n",
        "TUAB・TUEVどちらのデータセットを使っても良いと思ったが、どちらもTemple Universityへの要求方法が不明なため、質問済。"
      ],
      "metadata": {
        "id": "y9B--gvwROlz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "リポジトリを[/content/drive/My Drive/LaBraM]へダウンロード済 12/2"
      ],
      "metadata": {
        "id": "xhc-OS48JQwd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-Gv59BL-o81",
        "outputId": "39f4926a-388d-45f7-d741-ba38c0e8f4b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content\n",
            "Cloning into 'labram_repo'...\n",
            "remote: Enumerating objects: 124, done.\u001b[K\n",
            "remote: Counting objects: 100% (67/67), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 124 (delta 49), reused 45 (delta 42), pack-reused 57 (from 1)\u001b[K\n",
            "Receiving objects: 100% (124/124), 167.16 MiB | 26.39 MiB/s, done.\n",
            "Resolving deltas: 100% (55/55), done.\n",
            "Updating files: 100% (27/27), done.\n",
            "ディレクトリ構造:\n",
            "LaBraM/\n",
            "  checkpoints/\n",
            "    labram-base.pth/\n",
            "    vqnsp.pth/\n",
            "  data_processor/\n",
            "    data_preprocess.py/\n",
            "    dataset.py/\n",
            "  dataset_maker/\n",
            "    make_TUAB.py/\n",
            "    make_TUEV.py/\n",
            "    make_h5dataset_for_pretrain.py/\n",
            "    shock/\n",
            "      __init__.py/\n",
            "      utils/\n",
            "        __init__.py/\n",
            "        eegUtils.py/\n",
            "        h5.py/\n",
            "        ringBuffer.py/\n",
            "  engine_for_finetuning.py/\n",
            "  engine_for_pretraining.py/\n",
            "  engine_for_vqnsp.py/\n",
            "  labram.png/\n",
            "  modeling_finetune.py/\n",
            "  modeling_pretrain.py/\n",
            "  modeling_vqnsp.py/\n",
            "  norm_ema_quantizer.py/\n",
            "  optim_factory.py/\n",
            "  README.md/\n",
            "  requirements.txt/\n",
            "  run_class_finetuning.py/\n",
            "  run_labram_pretraining.py/\n",
            "  run_vqnsp_training.py/\n",
            "  utils.py/\n",
            "\n",
            "[checkpoints]フォルダの内容:\n",
            "  labram-base.pth\n",
            "  vqnsp.pth\n"
          ]
        }
      ],
      "source": [
        "# Google Driveをマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 保存先ディレクトリの設定\n",
        "import os\n",
        "drive_path = '/content/drive/My Drive/LaBraM'  # Drive内に保存するフォルダ名\n",
        "if not os.path.exists(drive_path):\n",
        "    os.makedirs(drive_path)\n",
        "\n",
        "# リポジトリをクローン\n",
        "repo_url = \"https://github.com/935963004/LaBraM.git\"  # GitHubのURL\n",
        "%cd /content\n",
        "!git clone {repo_url} labram_repo\n",
        "!cp -r labram_repo/* \"{drive_path}\"\n",
        "\n",
        "# ディレクトリ構造を表示\n",
        "import os\n",
        "\n",
        "def display_directory_structure(path, level=0):\n",
        "    indent = \"  \" * level\n",
        "    print(f\"{indent}{os.path.basename(path)}/\")\n",
        "    if os.path.isdir(path):\n",
        "        for item in os.listdir(path):\n",
        "            display_directory_structure(os.path.join(path, item), level + 1)\n",
        "\n",
        "print(\"ディレクトリ構造:\")\n",
        "display_directory_structure(drive_path)\n",
        "\n",
        "# 推奨ファイルを特定するために 'checkpoints' フォルダの内容を表示\n",
        "checkpoints_dir = os.path.join(drive_path, 'checkpoints')\n",
        "if os.path.exists(checkpoints_dir):\n",
        "    print(\"\\n[checkpoints]フォルダの内容:\")\n",
        "    for file in os.listdir(checkpoints_dir):\n",
        "        print(f\"  {file}\")\n",
        "else:\n",
        "    print(\"\\n[checkpoints]フォルダが存在しません。\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "大規模コードの木構造を特定 12/3"
      ],
      "metadata": {
        "id": "SfaPrArmER3F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ファインチューニング時にはGiTHubの以下のコマンドにより\n",
        "run_class_finetuning.pyが最初に起動される。"
      ],
      "metadata": {
        "id": "GGdteki6Kw8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OMP_NUM_THREADS=1 torchrun --nnodes=1 --nproc_per_node=8 run_class_finetuning.py \\\n",
        "        --output_dir ./checkpoints/finetune_tuab_base/ \\\n",
        "        --log_dir ./log/finetune_tuab_base \\\n",
        "        --model labram_base_patch200_200 \\\n",
        "        --finetune ./checkpoints/labram-base.pth \\    #baseモデルの重み\n",
        "        --weight_decay 0.05 \\\n",
        "        --batch_size 64 \\\n",
        "        --lr 5e-4 \\\n",
        "        --update_freq 1 \\\n",
        "        --warmup_epochs 3 \\\n",
        "        --epochs 30 \\\n",
        "        --layer_decay 0.65 \\\n",
        "        --drop_path 0.1 \\\n",
        "        --dist_eval \\\n",
        "        --save_ckpt_freq 5 \\\n",
        "        --disable_rel_pos_bias \\\n",
        "        --abs_pos_emb \\\n",
        "        --dataset TUAB \\   #これは明らかに変える必要ある。\n",
        "        --disable_qkv_bias \\\n",
        "        --seed 0"
      ],
      "metadata": {
        "id": "6GFLZizLMgK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "run_class_finetuning.pyから、以下の依存関係を特定した。"
      ],
      "metadata": {
        "id": "i24SlkJsMivZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_class_finetuning.py\n",
        "├── argparse (標準ライブラリ)\n",
        "├── datetime (標準ライブラリ)\n",
        "├── numpy (外部ライブラリ)\n",
        "├── time (標準ライブラリ)\n",
        "├── torch (外部ライブラリ)\n",
        "│   ├── torch.backends.cudnn\n",
        "│   ├── torch.utils.data\n",
        "│   └── torch.nn\n",
        "├── json (標準ライブラリ)\n",
        "├── os (標準ライブラリ)\n",
        "├── pathlib.Path (標準ライブラリ)\n",
        "├── collections.OrderedDict (標準ライブラリ)\n",
        "├── timm (外部ライブラリ)\n",
        "│   ├── timm.data.mixup.Mixup\n",
        "│   ├── timm.models.create_model\n",
        "│   ├── timm.loss.LabelSmoothingCrossEntropy\n",
        "│   ├── timm.loss.SoftTargetCrossEntropy\n",
        "│   └── timm.utils.ModelEma\n",
        "├── optim_factory.py     #最適化関連\n",
        "│   ├── create_optimizer\n",
        "│   ├── get_parameter_groups\n",
        "│   └── LayerDecayValueAssigner\n",
        "├── engine_for_finetuning.py  #ファインチューニング用のエンジン\n",
        "│   ├── train_one_epoch\n",
        "│   └── evaluate\n",
        "├── utils.py\n",
        "│   ├── NativeScalerWithGradNormCount   #学習率スケーリング\n",
        "│   ├── init_distributed_mode\n",
        "│   ├── create_ds_config\n",
        "│   ├── get_rank\n",
        "│   ├── cosine_scheduler\n",
        "│   ├── auto_load_model     #これを調査すると、恐らくモデル構造を論文以上に把握できるだろう。\n",
        "│   ├── save_model\n",
        "│   ├── is_main_process\n",
        "│   ├── prepare_TUAB_dataset   #ここを変える必要がある。 utils内のprepare_oo_dataset系\n",
        "│   ├── prepare_TUEV_dataset\n",
        "│   ├── TensorboardLogger\n",
        "│   └── load_state_dict\n",
        "├── modeling_finetune.py\n",
        "│   └── モデルの定義\n",
        "├── scipy.interpolate (外部ライブラリ)  #これはなんでインポートされてるか分からない...\n"
      ],
      "metadata": {
        "id": "VVOXJZstMu0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "run_class_finetuning.pyの実行時の関数呼び出し順序（木構造）"
      ],
      "metadata": {
        "id": "U-4XpUs2OGy9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_class_finetuning.py\n",
        "└── main(args, ds_init)\n",
        "    ├── utils.init_distributed_mode(args)\n",
        "    ├── デバイスとシードの設定\n",
        "    ├── cudnn.benchmark = True\n",
        "    ├── dataset_train, dataset_test, dataset_val, ch_names, metrics = get_dataset(args)\n",
        "    │   └── prepare_TUAB_dataset または prepare_TUEV_dataset（utils.py内）\n",
        "    ├── サンプラーとデータローダーの設定\n",
        "    │   ├── torch.utils.data.DistributedSampler（トレーニング用）\n",
        "    │   ├── torch.utils.data.SequentialSampler（検証・テスト用）\n",
        "    │   └── torch.utils.data.DataLoader（データローダー作成）\n",
        "    ├── ロガーの設定（TensorboardLogger）\n",
        "    ├── model = get_models(args)\n",
        "    │   └── timm.models.create_model または modeling_finetune.py のモデル作成関数\n",
        "    ├── モデルの初期化と読み込み\n",
        "    │   ├── 事前学習済みモデルのロード（args.finetune が指定されている場合）\n",
        "    │   ├── モデルの重みの調整（必要に応じて）\n",
        "    │   └── モデルをデバイスに転送（model.to(device)）\n",
        "    ├── モデルEMAの設定（必要に応じて）\n",
        "    ├── DistributedDataParallel の設定（分散学習の場合）\n",
        "    ├── オプティマイザとスケジューラの設定\n",
        "    │   ├── optimizer = create_optimizer(...)\n",
        "    │   ├── loss_scaler = NativeScaler()\n",
        "    │   ├── lr_schedule_values = utils.cosine_scheduler(...)\n",
        "    │   └── wd_schedule_values = utils.cosine_scheduler(...)\n",
        "    ├── 損失関数の設定（criterion）\n",
        "    ├── utils.auto_load_model(...)（チェックポイントの自動ロード）\n",
        "    ├── トレーニングループ開始（エポックごとに繰り返し）\n",
        "    │   ├── data_loader_train.sampler.set_epoch(epoch)\n",
        "    │   ├── train_stats = train_one_epoch(...)\n",
        "    │   │   ├── モデルをトレーニングモードに設定（model.train()）\n",
        "    │   │   ├── バッチごとのトレーニングループ\n",
        "    │   │   │   ├── 入力データとラベルを取得\n",
        "    │   │   │   ├── optimizer.zero_grad()\n",
        "    │   │   │   ├── 出力の計算（outputs = model(inputs)）\n",
        "    │   │   │   ├── 損失の計算（loss = criterion(outputs, targets)）\n",
        "    │   │   │   ├── loss_scaler(loss, optimizer, ...)\n",
        "    │   │   │   └── 学習率と重み減衰の更新\n",
        "    │   │   └── 統計情報の収集\n",
        "    │   ├── モデルの保存（必要に応じて）\n",
        "    │   ├── 検証（data_loader_val がある場合）\n",
        "    │   │   ├── val_stats = evaluate(...)\n",
        "    │   │   │   ├── モデルを評価モードに設定（model.eval()）\n",
        "    │   │   │   ├── バッチごとの評価ループ\n",
        "    │   │   │   │   ├── 入力データとラベルを取得\n",
        "    │   │   │   │   ├── 出力の計算（outputs = model(inputs)）\n",
        "    │   │   │   │   ├── 損失の計算（loss = criterion(outputs, targets)）\n",
        "    │   │   │   │   └── 統計情報の収集（metrics の計算）\n",
        "    │   │   └── 検証結果の表示とログ記録\n",
        "    │   ├── テスト（data_loader_test がある場合）\n",
        "    │   │   ├── test_stats = evaluate(...)\n",
        "    │   │   └── テスト結果の表示とログ記録\n",
        "    │   ├── 最良モデルの保存（必要に応じて）\n",
        "    │   └── エポックごとのログの保存\n",
        "    └── トレーニング時間の計測と表示\n"
      ],
      "metadata": {
        "id": "C_noGJx1OMVp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}